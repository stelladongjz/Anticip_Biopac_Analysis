{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772d3cf3",
   "metadata": {},
   "source": [
    "# Data Processing Functions for AvAnt2025_AnalysisEKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8c208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/84ry5gsj3bnd86w91nlcyck00000gr/T/ipykernel_28427/3025049525.py:13: DeprecationWarning: Please import `pearsonr` from the `scipy.stats` namespace; the `scipy.stats.stats` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.stats.stats import pearsonr # Pearson's correlation\n",
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/magics/pylab.py:166: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame as DF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "#np.random.seed(sum(map(ord, \"distributions\")))\n",
    "from sklearn import linear_model  # packages for the logistic regression function to plot the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression # packages for the logistic regression function to plot the logistic regression \n",
    "import scipy\n",
    "from scipy import stats, integrate\n",
    "from scipy.stats import mode\n",
    "from scipy.stats.stats import pearsonr # Pearson's correlation\n",
    "from scipy.stats import sem\n",
    "from copy import copy as copy\n",
    "import operator as operator\n",
    "\n",
    "\n",
    "# Plotting tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from functools import reduce\n",
    "\n",
    "%pylab inline\n",
    "figsize(5, 5)\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "from ecgdetectors import Detectors\n",
    "\n",
    "# Added to avoid OMP:error#15\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5573160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set sample rate\n",
    "sampleRate = 100\n",
    "fs = sampleRate\n",
    "detectors = Detectors(sampleRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176cc0a2",
   "metadata": {},
   "source": [
    "# Preprocess data & detect r-peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4d150",
   "metadata": {},
   "source": [
    "### Use ECG Detectors (two average detector) for r-peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71363ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Uses pank tompkins detector for r peak detection\n",
    "\n",
    "\n",
    "def preprocess(delaydata):\n",
    "    \"\"\"\n",
    "    preprocess data by adding r-peak information\n",
    "    parameters (delaydata): the full preprocessed dataframe\n",
    "    returns dataframe with added columns:\n",
    "        pEKG (raw ekg data)\n",
    "        peak (boolean value of wether a peak is detected at the current row)\n",
    "        peak_time: the time at which peak occurs\n",
    "    \"\"\"\n",
    "    delayProcessed = pd.DataFrame()\n",
    "\n",
    "    for participant in np.unique(delaydata['partNum']):\n",
    "        dataPart = delaydata[delaydata['partNum'] == participant].copy()\n",
    "        time =dataPart['time'].values\n",
    "        signal = dataPart.EKG.values \n",
    "        r_peaks = detectors.pan_tompkins_detector(signal)\n",
    "        peaks_mask = np.zeros_like(signal, dtype=bool)\n",
    "        peaks_mask[r_peaks] = True\n",
    "\n",
    "        dataPart['pEKG'] = signal #same as raw EKG value, changing the name for consistency purposes\n",
    "        dataPart['peak'] = peaks_mask\n",
    "        dataPart['peak_time'] = np.where(peaks_mask, time, np.nan)\n",
    "\n",
    "        delayProcessed = pd.concat([delayProcessed, dataPart], ignore_index=True)\n",
    "\n",
    "    return delayProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e5a93",
   "metadata": {},
   "source": [
    "# extract baseline using the start trial period (first 2 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10262b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBI_baseline(mergedDFClean):\n",
    "    dataBaseline = mergedDFClean\n",
    "    dataBaseline0= preprocess(dataBaseline)\n",
    "\n",
    "    ### create baseline IBI for each trial\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for participant in dataBaseline0['partNum'].unique():\n",
    "        part_data = dataBaseline0[dataBaseline0['partNum'] == participant]\n",
    "        for session in dataBaseline0['session'].unique():\n",
    "            sess_data = part_data[part_data['session'] == session]\n",
    "            \n",
    "            #compute baseline IBI at trial level\n",
    "            for trial in sess_data['trials'].unique():\n",
    "                trial_data = sess_data[sess_data['trials'] == trial]\n",
    "                part_trial = trial_data['PART_trial'].iloc[0]\n",
    "                delay      = trial_data['delay_time'].iloc[0]\n",
    "\n",
    "                \n",
    "                peak_idxs = np.where(trial_data['peak'])[0]        \n",
    "                \n",
    "                \n",
    "                if len(peak_idxs) < 2:\n",
    "                    mean_ibi = np.nan\n",
    "                \n",
    "                #divide ibi values by sample rate\n",
    "                else:\n",
    "                    ibi_samples = np.diff(peak_idxs)\n",
    "                    mean_ibi = ibi_samples.mean()/ sampleRate\n",
    "\n",
    "                rows.append({\n",
    "                    'participant': participant,\n",
    "                    'session': session,\n",
    "                    'trial': trial,\n",
    "                    'delay_time':  delay,\n",
    "                    'baseline': mean_ibi,\n",
    "                    'PART_trial': part_trial\n",
    "                    \n",
    "                })\n",
    "            \n",
    "    #return baseline_IBI\n",
    "    baseline_IBI = pd.DataFrame(rows)\n",
    "\n",
    "    \n",
    "    return baseline_IBI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3bb5a",
   "metadata": {},
   "source": [
    "# 1. Compute IBI intervals from before infochoice presentation till after stimulus presentation time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute IBI values by picking time windows 2s before info cue onset till 4s after stimulus onset, \n",
    "# normalize by subtracting baseline IBI values on the trial level\n",
    "# Parameters: data (dataframe to be computed IBI for); baseline_df (baseline values for this same set of data)\n",
    "\n",
    "def compute_IBI (data,baseline_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with one row per trial, containing:\n",
    "      - participant, delay_time, PART_trial\n",
    "      - IBIs: list of normalized IBIs (s)\n",
    "      - time_norm: list of IBI timestamps relative to window start (s)\n",
    "      - cue_norm, stim_norm: cue and stim onsets relative to window start (s)\n",
    "      *** remove outliers with IBI values > 2 (some trials have recording issues)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for trials in data['PART_trial'].unique():\n",
    "        trial_data = data[data['PART_trial']==trials]\n",
    "        participant = trial_data['partNum'].iloc[0]\n",
    "        delay = trial_data['delay_time'].iloc[0]\n",
    "\n",
    "        #extract time point stimInfo or stimNoInfo is presented\n",
    "        if 'stimInfoOnset' in trial_data.columns and trial_data['stimInfoOnset'].eq(1).any():\n",
    "            cueTime = trial_data.loc[trial_data['stimInfoOnset']==1, 'time'].iloc[0]\n",
    "        elif 'stimNoInfoOnset' in trial_data.columns and trial_data['stimNoInfoOnset'].eq(1).any():\n",
    "            cueTime = trial_data.loc[trial_data['stimNoInfoOnset']==1, 'time'].iloc[0]\n",
    "        else:\n",
    "            cueTime = np.nan\n",
    "\n",
    "        #extract time point scream or noScream is presented\n",
    "        if 'screamOnset' in trial_data.columns and trial_data['screamOnset'].eq(1).any():\n",
    "            stimTime = trial_data.loc[trial_data['screamOnset']==1,'time'].iloc[0]\n",
    "        elif 'noScreamOnset' in trial_data.columns and trial_data['noScreamOnset'].eq(1).any():\n",
    "            stimTime = trial_data.loc[trial_data['noScreamOnset']==1,'time'].iloc[0]    \n",
    "        else:\n",
    "            stimTime = np.nan\n",
    "\n",
    "        #define start and end time of where ibi values will be extracted\n",
    "        pre_window = 2.0 #adding 2 sec before infocue onset\n",
    "        post_window = 4.0 #adding 4 sec after outcome stimulus presentation (outcome pres + end trial time)\n",
    "        start = cueTime - pre_window\n",
    "        end = stimTime + post_window\n",
    "\n",
    "        \n",
    "        # restrict to peaks in that window\n",
    "        peak_times = trial_data.loc[trial_data['peak']==1, 'time'].values\n",
    "        in_window = peak_times[(peak_times >= start) & (peak_times <= end)]\n",
    "        if len(in_window) < 2:\n",
    "            continue\n",
    "        \n",
    "        #compute raw and normalized ibis\n",
    "        ibis      = np.diff(in_window)\n",
    "        ibi_times = (in_window[:-1] + in_window[1:]) / 2\n",
    "\n",
    "        # —— REMOVE OUTLIERS: drop any IBI > 2 seconds —— \n",
    "        mask = ibis < 2.0\n",
    "        ibis = ibis[mask]\n",
    "        ibi_times = ibi_times[mask]\n",
    "        if len(ibis) == 0:\n",
    "            # nothing left after filtering\n",
    "            continue\n",
    "\n",
    "        # —— normalize time to window start —— \n",
    "        t_norm     = (ibi_times - start).tolist()\n",
    "        cue_norm   = cueTime   - start\n",
    "        stim_norm  = stimTime  - start\n",
    "\n",
    "        base       = baseline_df.loc[\n",
    "                         baseline_df['PART_trial']==trials,'baseline'\n",
    "                     ].iloc[0]\n",
    "        ibis_norm  = (ibis - base).tolist()\n",
    "\n",
    "        \n",
    "        # get this trial’s delay_time (or whatever column you have)\n",
    "        delay = trial_data['delay_time'].iloc[0]\n",
    "\n",
    "        \n",
    "        # collect one row per IBI\n",
    "        rows.append({\n",
    "            'participant': participant,\n",
    "            'delay_time':  delay,\n",
    "            'PART_trial':  trials,\n",
    "            'IBIs':        ibis_norm,\n",
    "            'time_norm':   t_norm,\n",
    "            'cue_norm':    cue_norm,\n",
    "            'stim_norm':   stim_norm\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
